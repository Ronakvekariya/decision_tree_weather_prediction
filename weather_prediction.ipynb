{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b93862b-88f2-4359-8d2e-627cc35ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07934d8b-781e-445e-9465-b54db02e8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "500087bc-c69f-40b0-9b6a-6305237b350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145455</th>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145456</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145457</th>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145458</th>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145459</th>\n",
       "      <td>2017-06-25</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145460 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
       "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
       "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
       "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
       "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
       "...            ...      ...      ...      ...       ...          ...   \n",
       "145455  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
       "145456  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
       "145457  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
       "145458  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
       "145459  2017-06-25    Uluru     14.9      NaN       0.0          NaN   \n",
       "\n",
       "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  \\\n",
       "0            NaN           W           44.0          W  ...        71.0   \n",
       "1            NaN         WNW           44.0        NNW  ...        44.0   \n",
       "2            NaN         WSW           46.0          W  ...        38.0   \n",
       "3            NaN          NE           24.0         SE  ...        45.0   \n",
       "4            NaN           W           41.0        ENE  ...        82.0   \n",
       "...          ...         ...            ...        ...  ...         ...   \n",
       "145455       NaN           E           31.0         SE  ...        51.0   \n",
       "145456       NaN         NNW           22.0         SE  ...        56.0   \n",
       "145457       NaN           N           37.0         SE  ...        53.0   \n",
       "145458       NaN          SE           28.0        SSE  ...        51.0   \n",
       "145459       NaN         NaN            NaN        ESE  ...        62.0   \n",
       "\n",
       "        Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
       "0              22.0       1007.7       1007.1       8.0       NaN     16.9   \n",
       "1              25.0       1010.6       1007.8       NaN       NaN     17.2   \n",
       "2              30.0       1007.6       1008.7       NaN       2.0     21.0   \n",
       "3              16.0       1017.6       1012.8       NaN       NaN     18.1   \n",
       "4              33.0       1010.8       1006.0       7.0       8.0     17.8   \n",
       "...             ...          ...          ...       ...       ...      ...   \n",
       "145455         24.0       1024.6       1020.3       NaN       NaN     10.1   \n",
       "145456         21.0       1023.5       1019.1       NaN       NaN     10.9   \n",
       "145457         24.0       1021.0       1016.8       NaN       NaN     12.5   \n",
       "145458         24.0       1019.4       1016.5       3.0       2.0     15.1   \n",
       "145459         36.0       1020.2       1017.9       8.0       8.0     15.0   \n",
       "\n",
       "        Temp3pm  RainToday  RainTomorrow  \n",
       "0          21.8         No            No  \n",
       "1          24.3         No            No  \n",
       "2          23.2         No            No  \n",
       "3          26.5         No            No  \n",
       "4          29.7         No            No  \n",
       "...         ...        ...           ...  \n",
       "145455     22.4         No            No  \n",
       "145456     24.5         No            No  \n",
       "145457     26.1         No            No  \n",
       "145458     26.0         No            No  \n",
       "145459     20.9         No           NaN  \n",
       "\n",
       "[145460 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db556b2-dc7c-4951-88b8-48d591d34eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = ['RainTomorrow'] ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd36302c-daab-4f55-8ed4-481e41e883a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 142193 entries, 0 to 145458\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           142193 non-null  object \n",
      " 1   Location       142193 non-null  object \n",
      " 2   MinTemp        141556 non-null  float64\n",
      " 3   MaxTemp        141871 non-null  float64\n",
      " 4   Rainfall       140787 non-null  float64\n",
      " 5   Evaporation    81350 non-null   float64\n",
      " 6   Sunshine       74377 non-null   float64\n",
      " 7   WindGustDir    132863 non-null  object \n",
      " 8   WindGustSpeed  132923 non-null  float64\n",
      " 9   WindDir9am     132180 non-null  object \n",
      " 10  WindDir3pm     138415 non-null  object \n",
      " 11  WindSpeed9am   140845 non-null  float64\n",
      " 12  WindSpeed3pm   139563 non-null  float64\n",
      " 13  Humidity9am    140419 non-null  float64\n",
      " 14  Humidity3pm    138583 non-null  float64\n",
      " 15  Pressure9am    128179 non-null  float64\n",
      " 16  Pressure3pm    128212 non-null  float64\n",
      " 17  Cloud9am       88536 non-null   float64\n",
      " 18  Cloud3pm       85099 non-null   float64\n",
      " 19  Temp9am        141289 non-null  float64\n",
      " 20  Temp3pm        139467 non-null  float64\n",
      " 21  RainToday      140787 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 26.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95ce8abc-4d79-4427-83a1-26a5038b9354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'number of data per year'}, xlabel='Date', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"number of data per year\")\n",
    "sns.countplot(x = pd.to_datetime(data.Date).dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f556ce9-674c-47fe-8733-4f8d9dd48b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.to_datetime(data.Date).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b587f0-250f-46f0-afcd-39221e83c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[x <2015]\n",
    "val_data = data[x == 2015]\n",
    "test_data = data[x > 2015]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c887a4f0-a1df-47d0-bfda-f0cb14238be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98988"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "481baf59-ba45-4ec3-a006-c78adf1bf329",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_input = data.columns[1:-1]\n",
    "column_target = 'RainTomorrow'\n",
    "train_input = train_data[column_input].copy()\n",
    "train_output = train_data[column_target]\n",
    "\n",
    "val_input = val_data[column_input].copy()\n",
    "val_output = val_data[column_target]\n",
    "\n",
    "test_input = test_data[column_input].copy()\n",
    "test_output = test_data[column_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d403a138-7cfd-4e59-96b2-6307069f9ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144548</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>16.9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSE</td>\n",
       "      <td>43.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>1009.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.7</td>\n",
       "      <td>31.8</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144549</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>15.1</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>31.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>SW</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.9</td>\n",
       "      <td>34.8</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144550</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>17.3</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1011.9</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144551</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>20.1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESE</td>\n",
       "      <td>43.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>SSW</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>37.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144552</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>22.5</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>76.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>SSW</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1006.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>37.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98988 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0        Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1        Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2        Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3        Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4        Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "...         ...      ...      ...       ...          ...       ...   \n",
       "144548    Uluru     16.9     33.2       0.0          NaN       NaN   \n",
       "144549    Uluru     15.1     36.8       0.0          NaN       NaN   \n",
       "144550    Uluru     17.3     37.8       0.0          NaN       NaN   \n",
       "144551    Uluru     20.1     38.5       0.0          NaN       NaN   \n",
       "144552    Uluru     22.5     39.6       0.0          NaN       NaN   \n",
       "\n",
       "       WindGustDir  WindGustSpeed WindDir9am WindDir3pm  ...  WindSpeed3pm  \\\n",
       "0                W           44.0          W        WNW  ...          24.0   \n",
       "1              WNW           44.0        NNW        WSW  ...          22.0   \n",
       "2              WSW           46.0          W        WSW  ...          26.0   \n",
       "3               NE           24.0         SE          E  ...           9.0   \n",
       "4                W           41.0        ENE         NW  ...          20.0   \n",
       "...            ...            ...        ...        ...  ...           ...   \n",
       "144548         SSE           43.0        ESE        SSE  ...          26.0   \n",
       "144549          NE           31.0        ENE         SW  ...          20.0   \n",
       "144550         ESE           39.0        ESE        SSE  ...           9.0   \n",
       "144551         ESE           43.0        ESE        SSW  ...          17.0   \n",
       "144552         WNW           76.0        ENE        SSW  ...          13.0   \n",
       "\n",
       "        Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  \\\n",
       "0              71.0         22.0       1007.7       1007.1       8.0   \n",
       "1              44.0         25.0       1010.6       1007.8       NaN   \n",
       "2              38.0         30.0       1007.6       1008.7       NaN   \n",
       "3              45.0         16.0       1017.6       1012.8       NaN   \n",
       "4              82.0         33.0       1010.8       1006.0       7.0   \n",
       "...             ...          ...          ...          ...       ...   \n",
       "144548         22.0         13.0       1014.1       1009.8       NaN   \n",
       "144549         16.0          8.0       1012.6       1007.6       NaN   \n",
       "144550         15.0          8.0       1011.9       1008.0       NaN   \n",
       "144551         22.0          9.0       1014.0       1009.2       NaN   \n",
       "144552         16.0          9.0       1012.1       1006.2       NaN   \n",
       "\n",
       "        Cloud3pm  Temp9am  Temp3pm  RainToday  \n",
       "0            NaN     16.9     21.8         No  \n",
       "1            NaN     17.2     24.3         No  \n",
       "2            2.0     21.0     23.2         No  \n",
       "3            NaN     18.1     26.5         No  \n",
       "4            8.0     17.8     29.7         No  \n",
       "...          ...      ...      ...        ...  \n",
       "144548       NaN     23.7     31.8         No  \n",
       "144549       NaN     28.9     34.8         No  \n",
       "144550       NaN     29.7     35.7         No  \n",
       "144551       NaN     29.8     37.2         No  \n",
       "144552       NaN     30.1     37.4         No  \n",
       "\n",
       "[98988 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1ebbb0-31a0-41ce-88cc-d1522704cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col = data.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_col = data.select_dtypes(include= 'object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db2ea3b0-91fb-44f3-b6a7-bc3d094113d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col.remove('RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b40ace70-9fe9-4cb0-a0a1-a73b75598581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(skip_complete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d52caf52-ec8b-4f37-b1fd-02d2ff622755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:800: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imputer = imputer.fit(data[numeric_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f400a8-7719-43d4-8c8c-538799a025cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input[numeric_col] = imputer.transform(train_input[numeric_col])\n",
    "test_input[numeric_col] = imputer.transform(test_input[numeric_col])\n",
    "val_input[numeric_col] = imputer.transform(val_input[numeric_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1579c505-082a-4409-a0fc-ca4cbadcfd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp          0\n",
      "MaxTemp          0\n",
      "Rainfall         0\n",
      "Evaporation      0\n",
      "Sunshine         0\n",
      "WindGustSpeed    0\n",
      "WindSpeed9am     0\n",
      "WindSpeed3pm     0\n",
      "Humidity9am      0\n",
      "Humidity3pm      0\n",
      "Pressure9am      0\n",
      "Pressure3pm      0\n",
      "Cloud9am         0\n",
      "Cloud3pm         0\n",
      "Temp9am          0\n",
      "Temp3pm          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_input[numeric_col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22bb997d-5db5-4204-a157-d48b3862bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler , OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "330e1bcf-69e8-46f3-919e-1426be096e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(data[numeric_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cb3b28f-1703-48c8-97f1-2dffbecb53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input[numeric_col] = scaler.transform(train_input[numeric_col])\n",
    "test_input[numeric_col] = scaler.transform(test_input[numeric_col])\n",
    "val_input[numeric_col] = scaler.transform(val_input[numeric_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edb3243d-c555-4947-a61a-d5da4a561a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>0.469340</td>\n",
       "      <td>0.724008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>0.898480</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.105792</td>\n",
       "      <td>0.177039</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.731286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.839319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.881385</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.097422</td>\n",
       "      <td>0.233118</td>\n",
       "      <td>0.691983</td>\n",
       "      <td>0.836852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.814745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.918962</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.035593</td>\n",
       "      <td>0.189385</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.813820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>0.813679</td>\n",
       "      <td>0.716446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074069</td>\n",
       "      <td>0.432503</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.547107</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.729958</td>\n",
       "      <td>0.696737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>0.648585</td>\n",
       "      <td>0.756144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061520</td>\n",
       "      <td>0.487745</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.609917</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.631927</td>\n",
       "      <td>0.691983</td>\n",
       "      <td>0.727447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144913</th>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.746692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>0.788966</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.540496</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.253340</td>\n",
       "      <td>0.278878</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.737044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144914</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.778828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084346</td>\n",
       "      <td>0.964384</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.565289</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.066608</td>\n",
       "      <td>0.139280</td>\n",
       "      <td>0.715190</td>\n",
       "      <td>0.775432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144915</th>\n",
       "      <td>0.613208</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>0.922334</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.530579</td>\n",
       "      <td>0.4864</td>\n",
       "      <td>0.017109</td>\n",
       "      <td>0.204811</td>\n",
       "      <td>0.744726</td>\n",
       "      <td>0.769674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144916</th>\n",
       "      <td>0.672170</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085261</td>\n",
       "      <td>0.936046</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.195402</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.441322</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.812236</td>\n",
       "      <td>0.840691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144917</th>\n",
       "      <td>0.655660</td>\n",
       "      <td>0.797732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.265075</td>\n",
       "      <td>0.274976</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.790787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17231 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "2133    0.469340  0.724008       0.0     0.059423  0.898480       0.186047   \n",
       "2134    0.566038  0.839319       0.0     0.073467  0.881385       0.387597   \n",
       "2135    0.603774  0.814745       0.0     0.069600  0.918962       0.325581   \n",
       "2136    0.813679  0.716446       0.0     0.074069  0.432503       0.271318   \n",
       "2137    0.648585  0.756144       0.0     0.061520  0.487745       0.209302   \n",
       "...          ...       ...       ...          ...       ...            ...   \n",
       "144913  0.683962  0.746692       0.0     0.086477  0.788966       0.356589   \n",
       "144914  0.625000  0.778828       0.0     0.084346  0.964384       0.372093   \n",
       "144915  0.613208  0.792060       0.0     0.085020  0.922334       0.387597   \n",
       "144916  0.672170  0.826087       0.0     0.085261  0.936046       0.410853   \n",
       "144917  0.655660  0.797732       0.0     0.074761  0.840449       0.387597   \n",
       "\n",
       "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
       "2133        0.053846      0.126437         0.45         0.14     0.545455   \n",
       "2134        0.069231      0.103448         0.45         0.12     0.586777   \n",
       "2135        0.153846      0.229885         0.35         0.19     0.618182   \n",
       "2136        0.053846      0.080460         0.46         0.37     0.547107   \n",
       "2137        0.053846      0.103448         0.60         0.34     0.609917   \n",
       "...              ...           ...          ...          ...          ...   \n",
       "144913      0.269231      0.229885         0.23         0.12     0.540496   \n",
       "144914      0.230769      0.356322         0.17         0.07     0.565289   \n",
       "144915      0.253846      0.252874         0.12         0.07     0.530579   \n",
       "144916      0.153846      0.195402         0.12         0.12     0.441322   \n",
       "144917      0.153846      0.321839         0.46         0.18     0.442975   \n",
       "\n",
       "        Pressure3pm  Cloud9am  Cloud3pm   Temp9am   Temp3pm  \n",
       "2133         0.5424  0.105792  0.177039  0.594937  0.731286  \n",
       "2134         0.5648  0.097422  0.233118  0.691983  0.836852  \n",
       "2135         0.5632  0.035593  0.189385  0.767932  0.813820  \n",
       "2136         0.5600  0.888889  0.555556  0.729958  0.696737  \n",
       "2137         0.6016  0.888889  0.631927  0.691983  0.727447  \n",
       "...             ...       ...       ...       ...       ...  \n",
       "144913       0.5280  0.253340  0.278878  0.664557  0.737044  \n",
       "144914       0.5408  0.066608  0.139280  0.715190  0.775432  \n",
       "144915       0.4864  0.017109  0.204811  0.744726  0.769674  \n",
       "144916       0.4080  0.007556  0.111111  0.812236  0.840691  \n",
       "144917       0.4256  0.265075  0.274976  0.696203  0.790787  \n",
       "\n",
       "[17231 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_input[numeric_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a5a4020-b352-490e-8fc6-8cd19f9344ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col.remove('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78224582-84a1-45bf-b930-b0cee7c134dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location          0\n",
       "WindGustDir    6943\n",
       "WindDir9am     7323\n",
       "WindDir3pm     2030\n",
       "RainToday      1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[cat_col].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efd0e590-b14d-4008-a80d-640bc61dc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input[cat_col] = train_input[cat_col].fillna('Unknown')\n",
    "test_input[cat_col] = test_input[cat_col].fillna('Unknown')\n",
    "val_input[cat_col] = val_input[cat_col].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f558d3-023a-42ea-b4f9-7a7b36a3564e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location       0\n",
       "WindGustDir    0\n",
       "WindDir9am     0\n",
       "WindDir3pm     0\n",
       "RainToday      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[cat_col].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69660819-dac9-4b22-aaca-d3052b8e77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(data[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0daf1837-0f94-4b26-8781-534e4db9777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cat_col = list(encoder.get_feature_names_out(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0ee18d8-caad-4d07-904c-bf4b3d7d7cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83c22bb4-48a2-45c3-ac44-5d8e5b91dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\2105281140.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n"
     ]
    }
   ],
   "source": [
    "train_input[encoder_cat_col] = encoder.transform(train_input[cat_col])\n",
    "test_input[encoder_cat_col] = encoder.transform(test_input[cat_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a4f3812-d5a1-4296-a863-1faac75f941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n",
      "C:\\Users\\DC\\AppData\\Local\\Temp\\ipykernel_10644\\1142006350.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])\n"
     ]
    }
   ],
   "source": [
    "val_input[encoder_cat_col] = encoder.transform(val_input[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e2944fb-711e-4437-846b-63233fa74b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "      <th>WindDir3pm_nan</th>\n",
       "      <th>RainToday_No</th>\n",
       "      <th>RainToday_Yes</th>\n",
       "      <th>RainToday_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.681604</td>\n",
       "      <td>0.801512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074086</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>ENE</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.693396</td>\n",
       "      <td>0.725898</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.066050</td>\n",
       "      <td>0.371274</td>\n",
       "      <td>SSE</td>\n",
       "      <td>0.341085</td>\n",
       "      <td>SSE</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.634434</td>\n",
       "      <td>0.527410</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.322809</td>\n",
       "      <td>ENE</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>ESE</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.608491</td>\n",
       "      <td>0.538752</td>\n",
       "      <td>0.042049</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.217052</td>\n",
       "      <td>SSE</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>SE</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>0.204244</td>\n",
       "      <td>ENE</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>SE</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145454</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.502836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033413</td>\n",
       "      <td>0.683891</td>\n",
       "      <td>E</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>ESE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145455</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>0.266509</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>0.723197</td>\n",
       "      <td>E</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>SE</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145456</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>0.285377</td>\n",
       "      <td>0.568998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.775079</td>\n",
       "      <td>NNW</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>SE</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145457</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043234</td>\n",
       "      <td>0.719519</td>\n",
       "      <td>N</td>\n",
       "      <td>0.240310</td>\n",
       "      <td>SE</td>\n",
       "      <td>WNW</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145458</th>\n",
       "      <td>Uluru</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>0.601134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046595</td>\n",
       "      <td>0.726371</td>\n",
       "      <td>SE</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>SSE</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25974 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location   MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "2498     Albury  0.681604  0.801512  0.000000     0.074086  0.600345   \n",
       "2499     Albury  0.693396  0.725898  0.001078     0.066050  0.371274   \n",
       "2500     Albury  0.634434  0.527410  0.005930     0.045662  0.322809   \n",
       "2501     Albury  0.608491  0.538752  0.042049     0.038498  0.217052   \n",
       "2502     Albury  0.566038  0.523629  0.018329     0.024857  0.204244   \n",
       "...         ...       ...       ...       ...          ...       ...   \n",
       "145454    Uluru  0.283019  0.502836  0.000000     0.033413  0.683891   \n",
       "145455    Uluru  0.266509  0.533081  0.000000     0.036837  0.723197   \n",
       "145456    Uluru  0.285377  0.568998  0.000000     0.037205  0.775079   \n",
       "145457    Uluru  0.327830  0.599244  0.000000     0.043234  0.719519   \n",
       "145458    Uluru  0.384434  0.601134  0.000000     0.046595  0.726371   \n",
       "\n",
       "       WindGustDir  WindGustSpeed WindDir9am WindDir3pm  ...  WindDir3pm_SSE  \\\n",
       "2498           ENE       0.372093    Unknown        ESE  ...             0.0   \n",
       "2499           SSE       0.341085        SSE         SE  ...             0.0   \n",
       "2500           ENE       0.325581        ESE        ENE  ...             0.0   \n",
       "2501           SSE       0.255814         SE        SSE  ...             1.0   \n",
       "2502           ENE       0.193798         SE        SSE  ...             1.0   \n",
       "...            ...            ...        ...        ...  ...             ...   \n",
       "145454           E       0.193798        ESE          E  ...             0.0   \n",
       "145455           E       0.193798         SE        ENE  ...             0.0   \n",
       "145456         NNW       0.124031         SE          N  ...             0.0   \n",
       "145457           N       0.240310         SE        WNW  ...             0.0   \n",
       "145458          SE       0.170543        SSE          N  ...             0.0   \n",
       "\n",
       "        WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  \\\n",
       "2498               0.0            0.0           0.0             0.0   \n",
       "2499               0.0            0.0           0.0             0.0   \n",
       "2500               0.0            0.0           0.0             0.0   \n",
       "2501               0.0            0.0           0.0             0.0   \n",
       "2502               0.0            0.0           0.0             0.0   \n",
       "...                ...            ...           ...             ...   \n",
       "145454             0.0            0.0           0.0             0.0   \n",
       "145455             0.0            0.0           0.0             0.0   \n",
       "145456             0.0            0.0           0.0             0.0   \n",
       "145457             0.0            0.0           0.0             1.0   \n",
       "145458             0.0            0.0           0.0             0.0   \n",
       "\n",
       "        WindDir3pm_WSW  WindDir3pm_nan  RainToday_No  RainToday_Yes  \\\n",
       "2498               0.0             0.0           1.0            0.0   \n",
       "2499               0.0             0.0           1.0            0.0   \n",
       "2500               0.0             0.0           0.0            1.0   \n",
       "2501               0.0             0.0           0.0            1.0   \n",
       "2502               0.0             0.0           0.0            1.0   \n",
       "...                ...             ...           ...            ...   \n",
       "145454             0.0             0.0           1.0            0.0   \n",
       "145455             0.0             0.0           1.0            0.0   \n",
       "145456             0.0             0.0           1.0            0.0   \n",
       "145457             0.0             0.0           1.0            0.0   \n",
       "145458             0.0             0.0           1.0            0.0   \n",
       "\n",
       "        RainToday_nan  \n",
       "2498              0.0  \n",
       "2499              0.0  \n",
       "2500              0.0  \n",
       "2501              0.0  \n",
       "2502              0.0  \n",
       "...               ...  \n",
       "145454            0.0  \n",
       "145455            0.0  \n",
       "145456            0.0  \n",
       "145457            0.0  \n",
       "145458            0.0  \n",
       "\n",
       "[25974 rows x 124 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74e69d38-1ec4-41ec-92af-dee0baa0f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_input[numeric_col + encoder_cat_col]\n",
    "x_test = test_input[numeric_col + encoder_cat_col]\n",
    "x_val = val_input[numeric_col + encoder_cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5414041b-4a90-4f72-9d7b-0e04c83a4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a58ed67-0104-41fb-9a1b-6f275ef68847",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "691e16de-ca17-41ce-90f1-0524574872e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train , train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "420e56a5-8117-48e5-b0ee-a96f994642e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b5cecec-6341-474b-913e-fd765a58a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score , confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a4cea7d-fe57-4af5-a5c5-3beb9115b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matr = confusion_matrix(train_predict , train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6d8db62-d9e9-41f1-9bb3-d459a1bd2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76705     2]\n",
      " [    0 22281]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf42c2ef-3129-42cc-a3c9-8f8bc51c563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predict = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35ab3039-ae5c-4fee-971f-a4ab8ce9e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(val_predict , val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b721555-8b8e-4a6e-ac8f-ea7d5950a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11792  1755]\n",
      " [ 1791  1893]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc1f666c-9c41-42b8-a535-1294b01da70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(val_predict , val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b638c24-5ec5-4190-886c-7f5449bb638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794208113284197\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e9dd454-0935-4d78-9936-caa20dd9ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.86920413e-02, 2.68475290e-02, 3.72881650e-02, 3.42442458e-02,\n",
       "       8.50563812e-02, 5.35204019e-02, 2.33373779e-02, 2.21247786e-02,\n",
       "       3.28889599e-02, 2.54319478e-01, 3.56319562e-02, 7.13713418e-02,\n",
       "       2.28555577e-02, 2.94229864e-02, 3.32198196e-02, 2.90455775e-02,\n",
       "       1.84461994e-03, 2.33756227e-03, 1.76599080e-03, 6.07074164e-04,\n",
       "       1.64391314e-03, 9.99174374e-04, 1.41359976e-03, 1.34493703e-03,\n",
       "       1.46620629e-03, 1.54084818e-03, 9.19932907e-04, 2.66406481e-03,\n",
       "       1.45925600e-03, 3.27990091e-04, 1.66212294e-03, 1.60096845e-03,\n",
       "       1.28893428e-04, 1.35516887e-03, 1.80335469e-03, 1.49953800e-03,\n",
       "       9.67872637e-04, 1.16886605e-03, 2.29052575e-03, 5.44854466e-04,\n",
       "       8.46652919e-04, 6.72118690e-04, 1.87074362e-03, 1.44656269e-03,\n",
       "       1.36343292e-03, 9.72761529e-04, 5.36569606e-04, 1.67715253e-03,\n",
       "       1.64781854e-03, 1.64901573e-03, 7.77667944e-04, 1.75988386e-03,\n",
       "       1.55478901e-03, 2.35004238e-03, 1.74445346e-03, 3.39192611e-04,\n",
       "       1.60826620e-03, 1.83477258e-04, 1.38326373e-03, 1.60011842e-03,\n",
       "       1.47079045e-03, 1.99336751e-03, 2.23019108e-03, 2.19111220e-03,\n",
       "       2.56406445e-04, 1.71180140e-03, 1.49404721e-03, 2.30139784e-03,\n",
       "       2.78758213e-03, 1.89561592e-03, 1.87495739e-03, 2.49155600e-03,\n",
       "       2.44674247e-03, 2.65859864e-03, 2.32522073e-03, 2.15204759e-03,\n",
       "       2.16121249e-03, 1.86050467e-03, 2.19241950e-03, 2.29161674e-03,\n",
       "       1.66293789e-03, 0.00000000e+00, 1.70561702e-03, 1.95878641e-03,\n",
       "       1.97398619e-03, 3.28762155e-03, 1.89819214e-03, 2.76119791e-03,\n",
       "       2.97436296e-03, 2.88870355e-03, 2.47796749e-03, 2.12852839e-03,\n",
       "       2.05872046e-03, 1.77901194e-03, 1.78371462e-03, 2.55077616e-03,\n",
       "       2.32663699e-03, 2.36690205e-03, 0.00000000e+00, 1.92177257e-03,\n",
       "       2.16793349e-03, 1.59567834e-03, 3.01903186e-03, 2.56758789e-03,\n",
       "       1.92099002e-03, 3.45828593e-03, 2.58129386e-03, 2.45402402e-03,\n",
       "       1.67303570e-03, 1.70178945e-03, 2.56505674e-03, 1.78683720e-03,\n",
       "       2.54637686e-03, 3.43368574e-03, 1.98609558e-03, 0.00000000e+00,\n",
       "       1.90694108e-03, 2.13481529e-03, 0.00000000e+00])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "347ff754-27a3-40bd-a39f-b306c74d033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Humidity3pm</td>\n",
       "      <td>0.254319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunshine</td>\n",
       "      <td>0.085056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pressure3pm</td>\n",
       "      <td>0.071371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WindGustSpeed</td>\n",
       "      <td>0.053520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainfall</td>\n",
       "      <td>0.037288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pressure9am</td>\n",
       "      <td>0.035632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evaporation</td>\n",
       "      <td>0.034244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Temp9am</td>\n",
       "      <td>0.033220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Humidity9am</td>\n",
       "      <td>0.032889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cloud3pm</td>\n",
       "      <td>0.029423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features  importance\n",
       "9     Humidity3pm    0.254319\n",
       "4        Sunshine    0.085056\n",
       "11    Pressure3pm    0.071371\n",
       "5   WindGustSpeed    0.053520\n",
       "2        Rainfall    0.037288\n",
       "10    Pressure9am    0.035632\n",
       "3     Evaporation    0.034244\n",
       "14        Temp9am    0.033220\n",
       "8     Humidity9am    0.032889\n",
       "13       Cloud3pm    0.029423"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = pd.DataFrame({'features' : x_train.columns , 'importance' : model.feature_importances_ }).sort_values('importance', ascending=False)\n",
    "dic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d393c91-64ea-4fee-be0a-04e8e4e56df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='importance', ylabel='features'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data = dic.head(10) , x='importance' , y = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ecf0aa4-5b33-4dfd-be1d-65ae21be572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "A decision tree classifier.\n",
       "\n",
       "Read more in the :ref:`User Guide <tree>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
       "    The function to measure the quality of a split. Supported criteria are\n",
       "    \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
       "    Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
       "\n",
       "splitter : {\"best\", \"random\"}, default=\"best\"\n",
       "    The strategy used to choose the split at each node. Supported\n",
       "    strategies are \"best\" to choose the best split and \"random\" to choose\n",
       "    the best random split.\n",
       "\n",
       "max_depth : int, default=None\n",
       "    The maximum depth of the tree. If None, then nodes are expanded until\n",
       "    all leaves are pure or until all leaves contain less than\n",
       "    min_samples_split samples.\n",
       "\n",
       "min_samples_split : int or float, default=2\n",
       "    The minimum number of samples required to split an internal node:\n",
       "\n",
       "    - If int, then consider `min_samples_split` as the minimum number.\n",
       "    - If float, then `min_samples_split` is a fraction and\n",
       "      `ceil(min_samples_split * n_samples)` are the minimum\n",
       "      number of samples for each split.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_samples_leaf : int or float, default=1\n",
       "    The minimum number of samples required to be at a leaf node.\n",
       "    A split point at any depth will only be considered if it leaves at\n",
       "    least ``min_samples_leaf`` training samples in each of the left and\n",
       "    right branches.  This may have the effect of smoothing the model,\n",
       "    especially in regression.\n",
       "\n",
       "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
       "    - If float, then `min_samples_leaf` is a fraction and\n",
       "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
       "      number of samples for each node.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_weight_fraction_leaf : float, default=0.0\n",
       "    The minimum weighted fraction of the sum total of weights (of all\n",
       "    the input samples) required to be at a leaf node. Samples have\n",
       "    equal weight when sample_weight is not provided.\n",
       "\n",
       "max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
       "    The number of features to consider when looking for the best split:\n",
       "\n",
       "        - If int, then consider `max_features` features at each split.\n",
       "        - If float, then `max_features` is a fraction and\n",
       "          `max(1, int(max_features * n_features_in_))` features are considered at\n",
       "          each split.\n",
       "        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
       "        - If \"log2\", then `max_features=log2(n_features)`.\n",
       "        - If None, then `max_features=n_features`.\n",
       "\n",
       "    Note: the search for a split does not stop until at least one\n",
       "    valid partition of the node samples is found, even if it requires to\n",
       "    effectively inspect more than ``max_features`` features.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls the randomness of the estimator. The features are always\n",
       "    randomly permuted at each split, even if ``splitter`` is set to\n",
       "    ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
       "    select ``max_features`` at random at each split before finding the best\n",
       "    split among them. But the best found split may vary across different\n",
       "    runs, even if ``max_features=n_features``. That is the case, if the\n",
       "    improvement of the criterion is identical for several splits and one\n",
       "    split has to be selected at random. To obtain a deterministic behaviour\n",
       "    during fitting, ``random_state`` has to be fixed to an integer.\n",
       "    See :term:`Glossary <random_state>` for details.\n",
       "\n",
       "max_leaf_nodes : int, default=None\n",
       "    Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
       "    Best nodes are defined as relative reduction in impurity.\n",
       "    If None then unlimited number of leaf nodes.\n",
       "\n",
       "min_impurity_decrease : float, default=0.0\n",
       "    A node will be split if this split induces a decrease of the impurity\n",
       "    greater than or equal to this value.\n",
       "\n",
       "    The weighted impurity decrease equation is the following::\n",
       "\n",
       "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
       "                            - N_t_L / N_t * left_impurity)\n",
       "\n",
       "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
       "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
       "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
       "\n",
       "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
       "    if ``sample_weight`` is passed.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "\n",
       "class_weight : dict, list of dict or \"balanced\", default=None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If None, all classes are supposed to have weight one. For\n",
       "    multi-output problems, a list of dicts can be provided in the same\n",
       "    order as the columns of y.\n",
       "\n",
       "    Note that for multioutput (including multilabel) weights should be\n",
       "    defined for each class of every column in its own dict. For example,\n",
       "    for four-class multilabel classification weights should be\n",
       "    [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
       "    [{1:1}, {2:5}, {3:1}, {4:1}].\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``\n",
       "\n",
       "    For multi-output, the weights of each column of y will be multiplied.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "ccp_alpha : non-negative float, default=0.0\n",
       "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
       "    subtree with the largest cost complexity that is smaller than\n",
       "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
       "    :ref:`minimal_cost_complexity_pruning` for details.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
       "    The classes labels (single output problem),\n",
       "    or a list of arrays of class labels (multi-output problem).\n",
       "\n",
       "feature_importances_ : ndarray of shape (n_features,)\n",
       "    The impurity-based feature importances.\n",
       "    The higher, the more important the feature.\n",
       "    The importance of a feature is computed as the (normalized)\n",
       "    total reduction of the criterion brought by that feature.  It is also\n",
       "    known as the Gini importance [4]_.\n",
       "\n",
       "    Warning: impurity-based feature importances can be misleading for\n",
       "    high cardinality features (many unique values). See\n",
       "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
       "\n",
       "max_features_ : int\n",
       "    The inferred value of max_features.\n",
       "\n",
       "n_classes_ : int or list of int\n",
       "    The number of classes (for single output problems),\n",
       "    or a list containing the number of classes for each\n",
       "    output (for multi-output problems).\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "n_outputs_ : int\n",
       "    The number of outputs when ``fit`` is performed.\n",
       "\n",
       "tree_ : Tree instance\n",
       "    The underlying Tree object. Please refer to\n",
       "    ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
       "    :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
       "    for basic usage of these attributes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DecisionTreeRegressor : A decision tree regressor.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The default values for the parameters controlling the size of the trees\n",
       "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
       "unpruned trees which can potentially be very large on some data sets. To\n",
       "reduce memory consumption, the complexity and size of the trees should be\n",
       "controlled by setting those parameter values.\n",
       "\n",
       "The :meth:`predict` method operates using the :func:`numpy.argmax`\n",
       "function on the outputs of :meth:`predict_proba`. This means that in\n",
       "case the highest predicted probabilities are tied, the classifier will\n",
       "predict the tied class with the lowest index in :term:`classes_`.\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       ".. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
       "\n",
       ".. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
       "       and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
       "\n",
       ".. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
       "       Learning\", Springer, 2009.\n",
       "\n",
       ".. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
       "       https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> from sklearn.model_selection import cross_val_score\n",
       ">>> from sklearn.tree import DecisionTreeClassifier\n",
       ">>> clf = DecisionTreeClassifier(random_state=0)\n",
       ">>> iris = load_iris()\n",
       ">>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
       "...                             # doctest: +SKIP\n",
       "...\n",
       "array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
       "        0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\dc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\sklearn\\tree\\_classes.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     ExtraTreeClassifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "774e1224-4488-4820-90ac-3dc285e202a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=7, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=7, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=7 , random_state=42)\n",
    "model.fit(x_train , train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "312673c5-8835-4485-85ad-24a9ef7f2881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476684042510203"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train , train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50e626bc-6187-464b-9317-17e383544280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831985831985832"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test , test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c58767c4-cafe-4aca-a9f3-905077681edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844582438628054"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_val , val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9276838c-b7d8-48ca-bc21-08992cb24278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   0.8086933086933087\n",
      "2   0.8166243166243167\n",
      "3   0.8244013244013244\n",
      "4   0.827057827057827\n",
      "5   0.8307538307538308\n",
      "6   0.8328328328328328\n",
      "7   0.831985831985832\n",
      "8   0.8337568337568337\n",
      "9   0.8305998305998306\n",
      "10   0.8291368291368292\n",
      "11   0.8308308308308309\n",
      "12   0.8268653268653269\n",
      "13   0.8237083237083237\n",
      "14   0.8176638176638177\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    model = DecisionTreeClassifier(max_depth=i , random_state=42)\n",
    "    model.fit(x_train , train_output)\n",
    "    print(i , \" \" ,model.score(x_test , test_output))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a46ca33-1948-4fd8-83b4-f9598bfbc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_depth_error(md):\n",
    "    model = DecisionTreeClassifier(max_depth=md, random_state=42)\n",
    "    model.fit(x_train, train_output)\n",
    "    train_acc = 1 - model.score(x_train, train_output)\n",
    "    val_acc = 1 - model.score(x_val, val_output)\n",
    "    return {'Max Depth': md, 'Training Error': train_acc, 'Validation Error': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3457db15-4aed-4f9c-bf18-bf44e04a5fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[57], line 3\u001b[0m, in \u001b[0;36mmax_depth_error\u001b[1;34m(md)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_depth_error\u001b[39m(md):\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39mmd, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(x_train, train_output)\n\u001b[0;32m      5\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(x_val, val_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors_df = pd.DataFrame([max_depth_error(md) for md in range(1, 21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fde37eef-bb8c-4521-bbec-75c91de861a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'errors_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43merrors_df\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'errors_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(errors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc3e9d-e9f0-469d-8eb1-c22f5161e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model  = DecisionTreeClassifier(max_depth=7 , random_state=42)\n",
    "model.fit(x_train , train_output)\n",
    "print(model.score(x_val , val_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27427384-893a-47b7-be1f-c9c8744ad840",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "080134d1-20c0-4bf7-a6fe-11153478ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the max_leaf_node =  2\n",
      "max_leaf_node 2   max_depth  1   0.8224711276188266\n",
      "max_leaf_node 2   max_depth  2   0.8224711276188266\n",
      "max_leaf_node 2   max_depth  3   0.8224711276188266\n",
      "max_leaf_node 2   max_depth  4   0.8224711276188266\n",
      "max_leaf_node 2   max_depth  5   0.8224711276188266\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m9\u001b[39m):        \n\u001b[0;32m      8\u001b[0m     best_model  \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth \u001b[38;5;241m=\u001b[39m i , max_leaf_nodes\u001b[38;5;241m=\u001b[39mu, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_leaf_node\u001b[39m\u001b[38;5;124m'\u001b[39m , count , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth \u001b[39m\u001b[38;5;124m'\u001b[39m,i ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m , best_model\u001b[38;5;241m.\u001b[39mscore(x_val , val_output))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(u \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m12\u001b[39m) :\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:284\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 284\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:208\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     ]:\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:388\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[0;32m    387\u001b[0m first_row \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\u001b[38;5;241m.\u001b[39mgetrow(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:262\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:276\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unpack_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:125\u001b[0m, in \u001b[0;36m_unpack_tuple\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    121\u001b[0m     np\u001b[38;5;241m.\u001b[39msubtract(ary[\u001b[38;5;241m1\u001b[39m:], ary[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], result[l_begin:l_begin \u001b[38;5;241m+\u001b[39m l_diff])\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unpack_tuple\u001b[39m(x):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Unpacks one-element tuples for use as return values \"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "u = 1;\n",
    "count = 2\n",
    "while(True):\n",
    "    count = 2**u;\n",
    "    u  = u + 1\n",
    "    print(\"for the max_leaf_node = \" , u)\n",
    "    for i in range(1,9):        \n",
    "        best_model  = DecisionTreeClassifier(max_depth = i , max_leaf_nodes=u, random_state=42)\n",
    "        best_model.fit(x_train , train_output)\n",
    "        print('max_leaf_node' , count , ' ','max_depth ',i ,' ' , best_model.score(x_val , val_output))\n",
    "    if(u > 12) :\n",
    "        break;\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b834b4-04a7-4514-a187-15d67dfe1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "aussie_rain = {\n",
    "    'model': model,\n",
    "    'imputer': imputer,\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'numeric_cols': numeric_col,\n",
    "    'categorical_cols': cat_col,\n",
    "    'encoded_cols': encoder_cat_col\n",
    "}\n",
    "\n",
    "joblib.dump(aussie_rain, 'aussie_rain.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "841f99d6-e6e0-4aa2-a7f0-b0bcbdd3bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).to_parquet('train_input.parquet')\n",
    "pd.DataFrame(train_output).to_parquet('train_output.parquet')\n",
    "pd.DataFrame(x_test).to_parquet('test_input.parquet')\n",
    "pd.DataFrame(test_output).to_parquet('test_output.parquet')\n",
    "pd.DataFrame(x_val).to_parquet('val_input.parquet')\n",
    "pd.DataFrame(val_output).to_parquet('val_output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f38f015-12d0-451d-aa35-42dc9252c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6bc5822-5bb1-4573-83f7-f9a8aa1944de",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = RandomForestClassifier(random_state=42 , n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7da25770-004e-404c-8f61-669e92499115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=1, random_state=42)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(x_train,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ce520b1-1a33-430d-89e4-1bb70c9c9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567697754047937\n"
     ]
    }
   ],
   "source": [
    "print(random_model.score(x_val,val_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9126a10d-72af-442b-825e-614d43441720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8446138446138446\n"
     ]
    }
   ],
   "source": [
    "print(random_model.score(x_test,test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a936f218-2694-43af-9173-74895ea8f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(count):\n",
    "    temp_model = RandomForestClassifier(random_state=42 , n_jobs= -1 , n_estimators=count)    \n",
    "    temp_model.fit(x_train,train_output)\n",
    "    score = temp_model.score(x_val,val_output)    \n",
    "    print(\"n_estimators : \" , count , \"accuracy : \" , score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df6f1832-0ba4-46be-8c38-6f0c8bb31eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators :  10 accuracy :  0.8449886831872787\n",
      "n_estimators :  20 accuracy :  0.8498636178979746\n",
      "n_estimators :  30 accuracy :  0.853809993616157\n",
      "n_estimators :  40 accuracy :  0.8552028321049272\n",
      "n_estimators :  50 accuracy :  0.8543323080494458\n"
     ]
    }
   ],
   "source": [
    "previous = 0.5  # Initialize error with a low value\n",
    "count = 0\n",
    "while True:\n",
    "    count += 10\n",
    "    score = randomforest(count)\n",
    "    if previous > score:\n",
    "        break\n",
    "    previous = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54427ab7-21fd-4c22-a860-b6bb2af16d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea00051b-f5ae-4322-aba8-9b549eed774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators :  100 accuracy :  0.8567697754047937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8567697754047937"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00833e7b-0025-4d15-af2b-d78adce9147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_param(**param):\n",
    "    model =  RandomForestClassifier(random_state=42 , n_jobs= -1 , **param).fit(x_train,train_output)\n",
    "    score_train = model.score(x_val,val_output)\n",
    "    score_val = model.score(x_val,val_output)\n",
    "    print(\"training score : \" , score_train , \" val score : \" , score_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "64a6f5ab-8ad5-4120-bcc4-b4e8487c9fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score :  0.8530555394347397  val score :  0.8530555394347397\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=120 , max_depth = 70 , max_features = 10  , min_samples_split = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6191a710-aa69-4109-aecd-d73d01d562aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "radom_model =  RandomForestClassifier(random_state=42 , n_jobs= -1 , n_estimators=120 , max_depth = 70 , max_features = 10  , min_samples_split = 90).fit(x_train,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "361d41ea-a6ac-4c48-8344-67f7ea8ba677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radom_model.joblib']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(radom_model , \"radom_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b7cb9a-18d6-4494-9efd-2c255d0708c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_model\u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m , n_jobs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m , min_impurity_decrease\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m , max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m , class_weight\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "new_model= RandomForestClassifier(random_state=42 , n_jobs= -1 , min_impurity_decrease=1e-7 , max_samples=0.9 , class_weight={'No': 1, 'Yes': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47d569-f876-481d-861c-cbc6000e2dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
